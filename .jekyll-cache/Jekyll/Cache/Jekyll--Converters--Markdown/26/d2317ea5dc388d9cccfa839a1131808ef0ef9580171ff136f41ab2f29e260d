I"∆<p>I was recently working on a python wrapper around grep.  I often find myself having to search for random patterns through tons of CSVs.  At work I have used some applications that have helped out, but inevitably I found that said applications are lacking in some way or another.  Maybe it‚Äôs that the application did not easily allow any kind of recursive searching, did not allow ways to specify certain directories to not even bother searching, or (godforbid!) it did not allow any kind of regular expression use.  I thought it‚Äôd be fun to try to whip up a little script that could meet my needs‚Ä¶.fun &amp; practical.  The code is available on my <a href="http://www.github.com/stubs/py_grep_parse">GitHub</a> (although it may have changed some from the time of this writing).</p>

<p>In a nutshell, the python script utilizes the <a href="https://docs.python.org/2/library/subprocess.html">Subprocess</a> module to call grep to look for a given regular expression.  In the example below I simply was looking for the pattern ‚Äúsmith‚Äù (case insensitive) in a directory appropriately named ‚Äútest_data‚Äù.
<img src="http://localhost:4000/public/unpack_arg_lists/photo0.png" alt="code0" class="center-image" /></p>

<p>The results are below:
<img src="http://localhost:4000/public/unpack_arg_lists/photo1.png" alt="code1" class="center-image" /></p>

<p>‚ÄúGreat!‚Äù, I thought.  Now I can make a <code class="language-plaintext highlighter-rouge">head</code> call to gather the given file‚Äôs column headers.  Seems simple enough. In this case, my test data was all in one directory appropriately name ‚Äútest_data‚Äù, so I did not think much of how to accomplish this task. We can use make a <code class="language-plaintext highlighter-rouge">head -1</code> call using the same Subprocess module
to collect the first row from the files we are working with (assuming that the files have column headers in the first row).</p>

<p>Before I can make the <code class="language-plaintext highlighter-rouge">head -1</code> call, I need to first parse the path to the file from the data yielded in the first column (as shown above). Lastly, I can pass the individual variables client &amp; file_name to the <code class="language-plaintext highlighter-rouge">os.path.join()</code> method to get a intelligently joined path. :
<img src="http://localhost:4000/public/unpack_arg_lists/photo2.png" alt="code2" class="center-image" /></p>

<h3 id="complicating-stuff">COMPLICATING STUFF</h3>
<p>Well what if your grep search finds hits at different depths of recursion?  For instance, what if the directory containing all the data I wished to grep looked something like this:
<img src="http://localhost:4000/public/unpack_arg_lists/photo3.png" alt="code3" class="center-image" /></p>

<p>Unfortunately, <code class="language-plaintext highlighter-rouge">os.path.join()</code> is a function call requiring separate positional arguments.  This means one cannot simply create a list of strings that are to be joined by <code class="language-plaintext highlighter-rouge">os.path.join()</code> to create the path to a file to pull headers for.
<img src="http://localhost:4000/public/unpack_arg_lists/photo4.png" alt="code4" class="center-image" /></p>

<p>This puzzled me for a while, but rather than immediately try to start coding a solution I made myself take a quick break and grab a coffee.  I had a feeling I had stumbled across something similar when I was reading through every Python text book I could find (back when I was reading a lot more than actually writing).</p>

<p>Sure enough I remembered reading about how to denote functions that could be called with arbitrary arguments lists using the ‚Äú*‚Äù character. The same character can also unpack arguments that are already in a list or tuple to be used for a function call that needs separate arguments‚Ä¶.like <code class="language-plaintext highlighter-rouge">os.path.join()</code>!
<img src="http://localhost:4000/public/unpack_arg_lists/photo5.png" alt="code5" class="center-image" /></p>

<p>Utilizing the almighty * I was able to easily grep files for a regex pattern &amp; pull header rows for any files that were reported as having matches by my previous grep call with one python script.
<img src="http://localhost:4000/public/unpack_arg_lists/photo6.png" alt="code6" class="center-image" /></p>

<h3 id="related-links">Related Links:</h3>
<ul>
  <li><a href="https://docs.python.org/2.7/tutorial/controlflow.html#unpacking-argument-lists">Python 2.7 Documentation</a></li>
</ul>
:ET